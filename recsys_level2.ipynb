{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "aNefBwu1VA7M"
   },
   "source": [
    "# Рекомендательная система на базе датасета **movielens**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "59_iZqNkVA7S"
   },
   "source": [
    "Один из наиболее известных датасетов в мире рекомендательных систем - Movielens 25M, содержащий рейтинги к фильмам, оставленные различными пользователями на одноименном сайте https://movielens.org/.\n",
    "\n",
    "Мы будем использовать мини-версию датасета, содержащую 100 тысяч записей рейтингов фильмов."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7MTzoxulVA7V"
   },
   "source": [
    "## Загрузка данных"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "I5fvYqJDVA7X"
   },
   "source": [
    "Для создания алгоритмов рекомендательной системы, будем использовать библиотеку **surprise**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rt05w2p2VA7Z"
   },
   "source": [
    "Установим её, если она ещё не установлена на компьютер."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "jZ0JToZrVA7c"
   },
   "outputs": [],
   "source": [
    "!pip install scikit-surprise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "jpq1v5WTVA7n"
   },
   "outputs": [],
   "source": [
    "from surprise import Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "78r_pDDhVA7v"
   },
   "source": [
    "Загружаем датасет из **surprise**. \n",
    "\n",
    "Для этого подтвердите, что вы хотете его скачать, набрав **Y** в появившемся диалоговом окне.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "SmxrH7dbHpm8"
   },
   "outputs": [],
   "source": [
    "IN_COLAB = False\n",
    "\n",
    "if IN_COLAB:\n",
    "    data = Dataset.load_builtin('ml-100k')\n",
    "else:\n",
    "    # загрузка датасета из архива ml-100k.zip\n",
    "    # !unzip ./ml-100k.zip -d ./data\n",
    "    from surprise import Reader\n",
    "    from surprise.dataset import BUILTIN_DATASETS\n",
    "    data = Dataset.load_from_file('./data/ml-100k/u.data', reader=Reader(**BUILTIN_DATASETS['ml-100k'].reader_params))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "M7FSaRcPVA74"
   },
   "source": [
    "## Визуализация данных"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_xcR-N4kVA76"
   },
   "source": [
    "Для удобной работы с данными загрузим библиотеку **pandas**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "IbXPCvMzVA78"
   },
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cBXvcnFRVA8J"
   },
   "source": [
    "Преобразуем данные к формату **pandas DataFrame**, для удобной работы с ними:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "4c78lO-xVA8L"
   },
   "outputs": [],
   "source": [
    "df = pd.DataFrame(data.raw_ratings, columns=['userId', 'movieId', 'rating', 'timestamp'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "z8iZfdnZVA8S"
   },
   "outputs": [],
   "source": [
    "df.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8lk_aMC6VA8a"
   },
   "source": [
    "*  Колонка **userId** - идентификаторы пользователей сайта movielens;\n",
    "*  Колонка **movieId** - идентификаторы фильмов;\n",
    "*  Колонка **rating** - оценки фильмов пользователями по шкале от 1 до 5;\n",
    "*  Колонка **timestamp** - это время оценки фильма пользователем. Данный формат представления времени показывает, сколько секунд прошло с 1 января 1970 года."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cGXqlWpiVA8c"
   },
   "source": [
    "Мы можем посмотреть, сколько уникальных значений находится в каждой из колонок."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "VwB6SrRHVA8e"
   },
   "outputs": [],
   "source": [
    "df.apply('nunique')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gdNUHvGaVA8l"
   },
   "source": [
    "Для корректной работы с графиками в python требуется загрузить специальную библиотеку\n",
    "**matplotlib**, программную библиотеку на языке python для визуализации данных двумерной и трехмерной графикой."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "pLiOWELmVA8n"
   },
   "outputs": [],
   "source": [
    "# включим отрисовку графиков непосредственно в ячейках тетрадки\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Tmcpr7aiVA8r"
   },
   "source": [
    "Посмотрим наглядно, как часто в датасете встречаются разные оценки:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "3XYMil_AVA8s"
   },
   "outputs": [],
   "source": [
    "df['rating'].value_counts().sort_index().plot.bar(title='Распределение рейтингов', rot=0);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sc4V13ojVA8x"
   },
   "source": [
    "## Разбиение выборки на обучающую и тестовую"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "feldOglfVA8z"
   },
   "source": [
    "Библиотека **surprise** высокоуровневая, и позволяет нам разбить данные на обучающую и тестовую выборки всего одной функцией **train_test_split()**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "wj01SJESVA80"
   },
   "outputs": [],
   "source": [
    "from surprise.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "oapSXAZ2VA84"
   },
   "source": [
    "Функция **train_test_split()** принимает на вход два параметра:\n",
    "*  **data** - данные\n",
    "*  **test_size** - доля тестовой выборки. Укажем 0,25, чтобы тестовая выборка составляла 25% от всей выборки."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "tL12glA_VA85"
   },
   "outputs": [],
   "source": [
    "trainset, testset = train_test_split(data, test_size=0.25, random_state=13)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Pjk90jTfVA89"
   },
   "source": [
    "## Построение простой модели"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "R4bUU2_iVA8-"
   },
   "outputs": [],
   "source": [
    "from surprise import SVD, KNNBasic\n",
    "from surprise import accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wIrqEcYHVA9C"
   },
   "source": [
    "Инициализируем алгоритм. Алгоритм SVD - один из самых распространенных методов матричной факторизации (представления матрицы в виде произведения нескольких матриц). Такое представление позволяет анализировать похожие матрицы и раскладывать их на так называемые \"компоненты\". А так же, восстанавливая матрицы их этих компонент - заполнять недостающие значения (в нашем случае - оценки). Почитать можно здесь: http://www.albertauyeung.com/post/python-matrix-factorization/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "U-C8PSgmVA9D"
   },
   "outputs": [],
   "source": [
    "algo = SVD()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "T46Qt-efVA9G"
   },
   "source": [
    "Тренируем на тренировочной выборке алгоритм."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "023_UmhzVA9I"
   },
   "outputs": [],
   "source": [
    "algo.fit(trainset);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PLr4X8_3VA9M"
   },
   "source": [
    "Делаем предсказание на тестовой выборке."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "bgtICWuYVA9N"
   },
   "outputs": [],
   "source": [
    "predictions = algo.test(testset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Vl2LGS6R_w5Y"
   },
   "outputs": [],
   "source": [
    "testset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "rvvw4w3aVA9R"
   },
   "outputs": [],
   "source": [
    "accuracy.rmse(predictions);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rc3RBERHVA9V"
   },
   "source": [
    "Написанный выше код можно переписать в одну строчку:\n",
    "\n",
    "```python\n",
    "predictions = algo.fit(trainset).test(testset)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gxA9DhnrVA9W"
   },
   "source": [
    "## Кросс-валидация"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3nfQSI8gVA9X"
   },
   "source": [
    "Обучая любой алгоритм машинного обучения мы, фактически, \"подгоняем\" модель под данные, которые ей подаём. Но, если подгонять слишком сильно, то модель переобучится. То есть модель начнёт запоминать ответы вместо того, чтобы выявлять закономерности. \n",
    "\n",
    "На графиках ниже точки тренировочной выборки:\n",
    "*  слева - недообученная модель (большая ошибка на тренировочной выборке; большая ошибка на тестовой выборке)\n",
    "*  посередине - хорошо обученная модель (маленькая ошибка на тренировочной выборке; маленькая ошибка на тестовой выборке)\n",
    "*  справа - переобученная модель (очень маленькая или нулевая ошибка на тренировочной выборке; большая ошибка на тестовой выборке)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7sdQG7kTVA9Y"
   },
   "source": [
    "<p align=\"center\">\n",
    "  <img src=\"https://drive.google.com/uc?id=1Eg4Xg4o-lhzrgqNNmNQCtB1RxNJmnmWx\" alt=\"Drawing\" style=\"width: 100px;\" width=\"700\"/>\n",
    "</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mYNhrqsNVA9Z"
   },
   "source": [
    "Таким образом, обучая модель, мы всегда уменьшаем ошибку на тренировочной выборке. Вместе с ошибкой на тренировочной выборке, падает и ошибка на тестовой. Но после какого-то момента, модель начинает переобучатся, и ошибка на тестовой выборке начинает расти, в то время, как ошибка на тренировочной выборке продолжает падать. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Xmuhn5RUVA9Z"
   },
   "source": [
    "<p align=\"center\">\n",
    "  <img src=\"https://drive.google.com/uc?id=1mvU_jJIe07tAoX82qODcpmTBctx0ReuT\" alt=\"Drawing\" style=\"width: 100px;\" width=\"700\"/>\n",
    "</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "k-m8IjEkVA9a"
   },
   "source": [
    "Может получится ситуация, когда мы видим маленькую ошибку нашей модели, и думаем, что она хорошая, но на самом деле она просто переобучилась, и на новых данных покажет плохой результат.\n",
    "\n",
    "Чтобы избежать такой ситуации можно использовать отложенную выборку. То есть мы разбиваем наши данные на **тренировочную** выборку, **тестовую** выборку и **отложенную** выборку. Соответственно, обучаем модель на тренировочной, в ходе обучения проверяем результат на тестовой выборке, а в конце обучения, чтобы оценить качество модели, ошибку считаем на отложенной выборке."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "D1VIGh4eVA9b"
   },
   "source": [
    "<p align=\"center\">\n",
    "  <img src=\"https://drive.google.com/uc?id=1lZeoYL-KN644_EPsYTyR2EK83tBFgod9\" alt=\"Drawing\" style=\"width: 100px;\" width=\"700\"/>\n",
    "</p>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6qQjDxYpVA9c"
   },
   "source": [
    "При таком подходе в обучении модели участвует только тренировочная выборка. Тестовую и отложенную мы используем только для проверки. Если у нас мало данных, отложенная выборка - непозволительная роскошь. \n",
    "\n",
    "Другой популярный подход это **кросс-валидация** или скользящий контроль. Суть метода заключается в том, что мы дераем не одно разбиение датесета, а несколько разбиений таким образом, чтобы все данные использовались и в обучении и для проверки. Такие разбиения называются **фолдами**. \n",
    "\n",
    "Преимущества такого подхожа в том, что мы используем все данные для обучения. Также это позволяет оценить устойчивость модели. Если ошибки полученные на разных фолдах сильно отличаются, что модель неустойчива.\n",
    "Недостаток метода в том, что нам нужно обучать не одну модель, а несколько (столько, сколько мы выбрали фолдов).\n",
    "\n",
    "На практике часто выбирают 5 фолдов."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZrMKa--nVA9d"
   },
   "source": [
    "<p align=\"center\">\n",
    "  <img src=\"https://drive.google.com/uc?id=1C9eHgCi30X08XaSScmjqIOT3ayBtBiFw\" alt=\"Drawing\" style=\"width: 100px;\" width=\"300\"/>\n",
    "</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "3Nm_zw-BVA9e"
   },
   "outputs": [],
   "source": [
    "from surprise.model_selection import cross_validate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VEPy4jGKVA9h"
   },
   "source": [
    "Используем функцию **cross_validate** из модуля **model_selection** библиотеки **surprise**.\n",
    "\n",
    "Функция принимает на вход:\n",
    "*  algo - алгоритм, который будем обучать.\n",
    "*  data - исходные данные. Обратите внимание, что данные передаём не разбитые на выборки.\n",
    "*  measures - метрики ошибок по которым мы хотим сравнивать модели. Мы передаём среднеквадратичную ошибку и среднюю ошибку.\n",
    "* cv - количество фолдов.\n",
    "*  verbose - параметр указывающий хотим ли мы увидеть подробный результат выполнения функции."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "0dzKI1AmVA9i"
   },
   "outputs": [],
   "source": [
    "algo = SVD()\n",
    "cross_validate(algo, data, measures=['RMSE', 'MAE'], cv=5, verbose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "D1ICfHrkVA9l"
   },
   "source": [
    "В результате получаем значения ошибок на каждом из фолдов, а также их среднее и стандартное отклонение (СО). Маленькое СО, как в нашем случае, говорит об устойчивости модели.\n",
    "\n",
    "Дополнительно мы видим время тренировки и время предсказания модели на каждом из фолдов."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qgBGv8BZVA9m"
   },
   "source": [
    "## Поиск по сетке (Grid search)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "j4L5ffx8VA9n"
   },
   "source": [
    "Теперь, когда у нас есть надёжный способ оценивать качество модели, мы можем перейти к подбору гиперпараметров модели, т.е. параметров, которые нужно указывать вручную, потому что нельзя обучить во время тренировки модели.\n",
    "\n",
    "Метод поиска по сетке очень прост. Мы передаём варианты каждого из параметров, который мы хотим перебрать, а функция перебирает все возможные варианты переданных параметров. Например, на картинке ниже перебираются параметры \"регуляризация\" и \"скорость обучения\"."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NfWrGyLhVA9s"
   },
   "source": [
    "<p align=\"center\">\n",
    "  <img src=\"https://drive.google.com/uc?id=1xs9z_Zo1A2QinErKYEB-bp6eGnLWodbO\" alt=\"Drawing\" style=\"width: 100px;\" width=\"700\"/>\n",
    "</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "7g8NQTNrVA9t"
   },
   "outputs": [],
   "source": [
    "from surprise.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Mt2Kc3qkVA9w"
   },
   "source": [
    "Зададим параметры, которые хотим перебрать:\n",
    "* n_epochs - количество эпох обучения.\n",
    "* lr_all - скорость обучения.\n",
    "* reg_all - регуляризация."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "QjWLzowlVA9y"
   },
   "outputs": [],
   "source": [
    "param_grid = {\n",
    "    'n_epochs': [5, 10], \n",
    "    'lr_all': [0.002, 0.005],\n",
    "    'reg_all': [0.4, 0.6]\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hvEIIGGeVA92"
   },
   "source": [
    "Для перебора по сетке используем функцию **GridSearchCV**. \n",
    "На вход подаём:\n",
    "* алгоритм.\n",
    "* параметры, которые хотим перебрать.\n",
    "* метрики ошибок.\n",
    "* количество фолдов для кросс-валидации.\n",
    "\n",
    "Обратите внимание, что функция выполняет кросс-валидация автоматически."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "4aYAdU2LVA93"
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "gs = GridSearchCV(SVD, param_grid, measures=['rmse', 'mae'], cv=5)\n",
    "gs.fit(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yvEhm53XVA96"
   },
   "source": [
    "Выведем лучший результат и лучшие найденные параметры."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "u9TbBBSHVA97"
   },
   "outputs": [],
   "source": [
    "print(gs.best_score['rmse'])\n",
    "print(gs.best_params['rmse'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0uoRiGroVA9_"
   },
   "source": [
    "Поскольку для того, чтобы перебрать очередной вариант параметров, нам нужно каждый раз обучать модель, такой поиск является ресурсозатратным и занимает много времени. По этой причине мы не можем перебрать большое количество комбинаций. Но, перебрав всего несколько, мы можем недостаточно приблизиться к оптимальному варианту.\n",
    "\n",
    "На практике мы обычно перебираем сначала несколько вариантов из большого диапазона параметров, а потом начинаем сужать диапазон, чтобы найти лчшую комбинацию. Например, если мы перебрали некоторый параметр *а* в диапазоне от 0.1 до 1 с шагом 0.1, т.е **[0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1.0]**, и лучшим оказался параметр **0.4**, то на следующей итерации мы можем попробовать перебрать диапазон от 0.3 до 0.5 с шагом 0.025, т.е. **[0.3, 0.325, 0.35, 0.375, 0.4, 0.425, 0.45, 0.475, 0.5]**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "aZOY7TawVA-A"
   },
   "source": [
    "**Задание:** Попробуйте найти параметры **n_epochs**, **lr_all**, **reg_all** для алгоритма **SVD** с помощью фукнции **GridSearchCV**, которые будут работать лучше, чем показанные в примере."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "tUo_Y70UVA-B"
   },
   "outputs": [],
   "source": [
    "# Ваш код здесь...\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "recsys_level2.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
